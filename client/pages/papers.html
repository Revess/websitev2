<!-- TODO: add about section for mobile online, move header text down into an about section. -->
<!doctype html>
<html>

<head>
</head>

<body>
  <div class="container-fluid pagesettings secondary">
    <div class="row">
      <div class="col-md-12 text-center">
        <h1>PAPERS</h1>
      </div>
    </div>
    <div class="row w-50 mx-auto">
      <div class="col-md-12 text-justify">
        <h3 class="text-center">Artificial Intelligence to generate live Algorithmic Dance Music</h3>
        <p class="text-warp">
          With the current state of AI music being impressive, but still not
          at its full capacity. Two factors are supposed culprits of this: audio
          quality and the speed of generating for live settings. The lack of stereo
          information and the struggle to retain phase information correctly are
          the culprits of this problem, the algorithms are computationally heavy
          and slow. This study aims to improve these problems and make the
          music more applicable so it can be used for a general audience. In
          this paper two options are proposed: A different interpretation to create datasets for GAN and using
          LSTM algorithms for generating data
          while playing the music live. By giving GAN algorithms both the complex and real domain during
          training
          for the entire stereo image the
          GAN converges way better with recreating this data. To test its applicability to a general audience,
          a
          group 53 participants were asked
          to identify 20 pieces of audio within 10 questions (so two samples per
          question). The group could give the audio either the label AI or Human. As a result, the group who
          did
          not have a musical background
          (playing or composing) and the ones who did not listen to instrumental music as often were not as
          able
          to recognize the difference between
          an AI or Human. The question is whether AI currently could replace
          human music. Concluding I would like to suggest a new genre as a
          result of this research: Algorithmic Dance Music. Since AI music is
          difficult to recreate as a human, due to the way frequencies are represented over time. ADM could be
          a
          new cultural movement where AI
          lives alongside human music.
        </p>
        <div class="text-center">
          <a href="./assets/pdf/Thesis.pdf" target="_blank">
            <button type="button" class="btn btn-primary btn-lg">Read More</button>
          </a>
        </div>
      </div>
    </div>
  </div>
</body>

</html>